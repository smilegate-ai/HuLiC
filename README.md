# HuLiC : [Human Like AI Conversation](https://hulic.smilegate.net/) 

![img](https://user-images.githubusercontent.com/95196586/147039219-4568c0c3-2551-42ed-b150-cf9e88b91d19.jpg)


> HuLiC은 인간의 “기능”을 흉내 내는 것이 아니라 “인간 다움”이란 무엇인가에 대해 진지하게 고민하고, 이를 AI 기술로 풀어낸 모델들을 평가하고 연구하여 지식을 공유하는 평가 플랫폼입니다.
> 인간처럼 상호작용을 하는 대화 모델을 평가하기 위해 적절한 평가 항목과 기준을 정의하고, 클라우드 소싱을 통해 다수의 워커가 같은 모델이 생성한 대화 데이터에 관해 평가를 진행했습니다.


### 데이터 구축 목적
***
기계적인 응답에서 벗어나 인간처럼 상호 작용하는 Human Like AI와 인간의 다양한 감성을 기술로 풀어내기 위해 연구하는 Fun AI가 만나 사람 같은 AI를 만들기 위한 연구에 기여하고자 본 데이터를 구축했습니다. 

#### 사람을 통한 데이터 구축 및 평가
* 대화 데이터 구축 및 평가의 전문 인력들이 봇과 대화를 하고, 평가하여 결과 데이터를 구축하는 방식
* 본 데이터를 활용하여 구축한 대화 모델의 성능을 향상시키는데 활용이 가능함
* 타사 유명 모델의 봇과 내 모델의 대화 수준을 비교할 수 있음
* 본 대화 데이터를 활용하여 사람과 봇의 대화 성능을 비교 분석할 수 있음


### 데이터 구축 방식
***
본 태스크는 스마일게이트 AI센터에서 인간과 유사하게 대화하는 오픈소스 대화 모델을 파악하고, 선별하여 자사가 만든 평가 기준과 워커들을 활용(정성적 평가)하여 평가받은 결과를 제공받는 방식으로 구축했습니다. 
사람과 사람의 대화 데이터의 경우 클라우드 워커들을 통해 영화를 주제로 대화하는 방식으로 데이터 구축 및 평가를 진행했습니다. 그 외에 사람과 봇의 일상대화 데이터의 경우 사람이 질문을 하고 봇이 답변을 하는 방식의 대화 데이터를 구축 및 평가를 진행했습니다. 

* 사람과 사람의 일상대화 데이터 구축
    - 롱 턴의 대화 데이터 구축
    - 4명의 전문 워커가 평가 진행
* 사람과 봇의 일상대화 데이터 구축
    - 내부 1차 평가 및 모델 선별
    - 20명의 전문 워커들이 대화 데이터 구축
    - 평가 항목에 맞게 2차 평가 진행


### 데이터 평가 방식
***
본 데이터의 평가는 장기간에 걸친 리서치와 다양한 사례를 기반으로 평가 항목을 정했으며, 정성적 평가로 워커마다 평가 기준이 상이함은 워커의 주관을 최대한 반영한 결과이므로 양해 부탁드립니다. 

#### 턴 별 평가 (0점과 1점으로 평가)
- 적절성 : 질문에 대한 답변이 얼마나 적절한지를 평가하는 항목
- 구체성 : 질문에 대한 답변이 얼마나 구체적인지를 평가하는 항목
- 인간유사도 : 질문에 대해 얼마나 사람과 유사하게 답변을 하는지를 평가하는 항목
#### 20턴 평가 (1점에서 5점까지 평가)
- 대화 선호도 : 20 턴 기준으로 대화한 내용이 얼마나 흥미로웠는지 또 대화하고 싶은지 등을 점수로 평가하는 항목 
    - 사람-사람 데이터의 경우 롱 턴의 대화 데이터를 제공하기 위해 대화를 멈추지 않고 최대한 이어서 진행하는 방식으로 구축. 20턴 마다 대화가 어땠는지를 평가해 주는 방식은 사람-봇 데이터와 동일하게 평가 진행(사람-사람 데이터의 경우 롱 턴의 일상대화 데이터 셋을 제공하고자 하는 목적에 초점을 맞추어 대화 데이터 구축)
    - 사람-봇 데이터의 경우 20턴 까지만 대화를 하게 하고, 20턴 마다 대화한 데이터를 평가하는 방식으로 진행 


### 데이터 설명
***
- 파일명 규칙 : [대화주제]_[model명].xlsx 
- 사람-사람 데이터: 사람과 사람이 영화를 주제로 대화한 내용을 워커가 항목에 맞게 평가한 결과로 데이터를 구축
    - 총 수량 : 40,000턴 (4명*10,000턴)
    - 사람-사람 데이터 샘플 
![image](https://user-images.githubusercontent.com/95196586/156349153-01183b3a-c3a2-4699-88e7-238abc3c6397.png)

- 사람-봇의 데이터: 오픈소스 대화 모델을 사용하여 워커와 대화를 진행하고 평가한 결과로 데이터를 구축
    - 총 수량 : 74,800턴 (20명*3740턴)
    - 사람-봇 데이터 샘플
![image](https://user-images.githubusercontent.com/95196586/156350536-db50b7fb-30f4-4503-b89c-6e70be6236d7.png)



#### 상세 설명
- Turn : Full_conversation에 해당하는 점수를 기재하기 위해 1~20 턴을 표기해 주는 정보(오픈소스 모델의 경우 한 대화가 20턴 기준으로 끊어지는 것 표기) 
- 작업자 : 평가자 구분 
- 나이 : 평가자의 나잇대 
- 성별 : 평가자의 성별
- 질문 : 사람의 질문
- 답변 : 모델의 답변(또는 사람의 답변)
- 평가 항목 : 적절성, 구체성, 인간 유사도, 대화 선호도 


#### 주의 사항
- 사람-사람 데이터와 사람-봇 데이터의 양과 평가 인원(worker)이 상이함
- 사람-봇 데이터의 경우 네이버 번역기를 사용하여 한글화한 대화 데이터로 평가 진행


### 참고 자료
***
- Blender 1.0 : https://parl.ai/projects/recipes, https://huggingface.co/facebook/blenderbot-400M-distill
- Blender 2.0 : https://parl.ai/projects/blenderbot2


### 문의
***
- E -mail : hulic@smilegate.com
- 주최 : Smilegate AI 센터
***

![logo_black_gray](https://user-images.githubusercontent.com/95196586/147066863-b9f99434-3ce8-463f-abb4-5e672b3a1fda.png)

                                                       

